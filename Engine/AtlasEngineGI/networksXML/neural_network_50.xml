<NeuralNetwork>
    <Inputs>
        <InputsNumber>12</InputsNumber>
        <Item Index="1">
            <Name>position.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>position.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>position.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="4">
            <Name>view.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="5">
            <Name>view.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="6">
            <Name>view.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="7">
            <Name>source.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="8">
            <Name>source.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="9">
            <Name>source.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="10">
            <Name>normal.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="11">
            <Name>normal.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="12">
            <Name>normal.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Inputs>
    <ScalingLayer>
        <ScalingNeuronsNumber>0</ScalingNeuronsNumber>
        <ScalingMethod>NoScaling</ScalingMethod>
    </ScalingLayer>
    <MultilayerPerceptron>
        <Architecture>12 20 10 3</Architecture>
        <LayersActivationFunction>HyperbolicTangent HyperbolicTangent Linear</LayersActivationFunction>
        <Parameters>-7.91741 -11.5195 -11.4406 2.71761 35.5156 -3.2456 -3.57076 36.0753 -8.09515 43.2441 0.15376 -2.53737 -0.0364018 15.1509 -91.653 40.001 52.5155 -115.853 10.6383 10.4161 22.1899 115.633 123.806 -37.9753 -12.6025 12.1392 -0.293075 7.4462 -7.74116 3.5966 2.19667 -1.93794 0.931361 -0.484162 -5.74711 -3.0898 -2.48255 1.06442 -0.0351865 2.56706 18.9363 0.77838 -12.6805 34.9102 7.32797 10.7731 -41.59 7.36448 -6.6458 2.02102 5.25005 -0.586671 2.54741 17.3182 8.21383 -12.8534 20.3117 -4.97902 7.51337 -27.051 -3.01619 -28.7933 0.405815 3.67567 -2.7201 3.14589 4.6237 -8.33589 -42.1666 -17.2821 3.63025 -0.0970944 -6.07709 6.39506 -2.29707 14.5923 -5.7153 4.33321 -4.56889 -37.5778 -13.6833 32.7575 -33.5521 -11.2351 -6.62076 35.8247 -12.7445 37.8149 1.28384 2.38613 -3.50809 1.7577 -1.23631 1.25082 -6.38906 -4.85318 7.35699 -4.76256 2.52636 8.60475 4.89287 0.0645819 -0.162089 2.28326 -2.6293 -19.9535 -1.28417 -18.1845 -19.6114 -7.48777 -15.7087 8.34569 -3.99497 12.2162 0.192297 -2.67856 -0.960767 2.4997 -72.0929 26.5197 3.11597 -18.6677 9.36921 -4.10412 -5.07451 10.1673 -3.71134 0.791954 -0.749088 1.82805 -1.33505 35.437 -45.2045 38.9391 23.4459 -26.8212 26.4553 40.5662 2.26077 11.0652 -5.07775 1.57339 -4.65316 2.94958 13.1672 7.60913 0.161863 -0.822289 19.626 2.82103 -2.14687 6.87215 -5.6758 -27.4334 -8.80644 -37.1027 -2.39609 -72.0324 -4.58678 -8.66466 20.9719 -27.2659 7.37047 -11.5901 -4.77059 5.26894 10.8874 -6.92471 0.0117233 1.15664 -10.7517 6.69634 -7.23121 -5.81515 3.51091 1.61113 -2.02159 9.70416 2.52893 -0.112664 0.967514 0.127869 -1.00713 8.55152 -11.2027 9.56137 0.883394 -7.95602 3.40244 -0.349315 -1.13963 2.51656 2.38101 0.682247 1.71671 1.17256 12.5454 -7.03964 -2.28579 -0.0170672 0.655909 1.33515 -3.05999 -0.552477 -1.76285 1.2845 2.04703 1.37674 2.71751 283.684 157.748 -633.19 1.80061 25.9066 9.37459 -5.84195 25.0199 13.7981 954.957 695.042 -330.69 4.74433 -31.6964 -1256.23 110.315 -41.2271 12.3135 -5.00863 15.4265 47.6133 50.6991 4.23136 10.5663 -4.40579 64.0042 -15.6171 -19.8346 -42.9672 -525.575 43.6222 40.0997 -283.594 55.9638 -388.646 4.74645 -0.81049 1.91725 -0.887305 0.406662 -2.53514 -14.0891 5.08889 -3.0627 -0.565177 -1.8876 -0.773886 6.14461 64.9341 -20.1384 36.2236 42.1857 37.9724 8.31271 -41.9842 -40.8502 -39.3489 48.5468 53.7531 43.4488 40.4215 52.1798 -42.2358 139.892 98.0764 41.6478 -39.3537 -33.8416 -36.1166 454.376 34.2266 -40.5716 -9.94576 9.25713 -9.77457 25.8834 23.6181 16.2163 11.1803 -15.3366 -12.0339 -10.9538 -10.8383 10.9715 13.5338 -8.54633 -11.8331 -5.90507 15.1582 35.0159 -8.88082 -17.8375 13.5393 -20.7364 1.15011 -17.0044 -2.57857 5.06125 -4.68731 -23.5396 12.9644 -2.27722 14.0223 -17.2495 5.22002 -14.6948 -2.29112 -17.4005 8.97828 -9.51579 1.6171 6.57658 9.48579 9.73479 -20.2813 -2.06933 -16.7283 17.4059 -14.5072 17.9637 -15.3983 7.94218 -22.639 1.46073 0.436117 2.54025 -15.474 2.77802 -9.99322 20.5792 5.24495 33.9084 2.29547 0.925413 7.5661 -104.69 258.206 -92.3431 126.316 96.2636 104.186 95.8087 -103.187 -112.889 -107.911 -104.472 104.634 -96.8278 623.92 -99.4094 269.887 99.2068 -239.816 256.983 -107.289 -103.547 14.304 -65.7061 -59.2839 -43.9354 67.0088 71.2497 12.0607 -63.3012 15.2503 22.2539 50.7994 -22.6333 -553.085 -145.76 15.3507 -21.0513 19.781 550.677 13.0939 -31.1829 -17.3859 18.3123 -2.08101 -7.59682 -29.7491 6.76274 -10.9439 25.7867 -5.531 5.81277 7.68392 7.94739 -6.44916 21.7987 6.89539 17.1539 -9.86119 -27.0129 -34.8024 -8.29666 -41.8939 -72.4524 30.5958 32.9742 -40.4901 4.23705 -15.4949 23.8553 -16.3797 -23.2366 48.3847 32.0709 13.4975 -22.4532 17.4905 21.973 30.4905 -38.6115 36.8643 -22.901 -16.1052 -25.1213 -51.2373 -32.8216 -14.7778 33.5886 40.9899 29.7183 13.6146 -37.943 -30.987 -32.6562 -37.7377 -57.1699 40.0659 -34.5315 -47.7596 -35.0858 41.8111 36.1794 19.1196 -11.9015 -31.4587 64.4214 20.2474 8.39794 -21.629 -7.8118 -4.68921 -8.0714 -2.01164 4.05305 10.9026 5.69467 3.13226 -18.6344 -28.5301 9.2155 21.1622 9.19452 18.7954 19.4352 43.4216 -135.902 9.57034 -0.0378607 -0.00156428 0.00427084 0.020728 0.00961235 0.000887361 -0.00368155 -0.00344003 0.0730746 -0.000617526 0.000536034 -0.00250598 -0.00171731 0.000813312 0.00226844 9.38765e-05 -0.00162532 0.000286981 -0.00285337 0.00694598 -0.000688172 0.00033321 -0.00155626 -0.000287023 0.00013583 0.00518068 -0.00463185 -0.00023662 -1.87061e-05 -0.000436587 0.00234288 -0.000141477 4.07698e-05</Parameters>
    </MultilayerPerceptron>
    <UnscalingLayer>
        <UnscalingNeuronsNumber>0</UnscalingNeuronsNumber>
        <UnscalingMethod>NoUnscaling</UnscalingMethod>
    </UnscalingLayer>
    <Outputs>
        <OutputsNumber>3</OutputsNumber>
        <Item Index="1">
            <Name>R</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>G</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>B</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Outputs>
</NeuralNetwork>
