<NeuralNetwork>
    <Inputs>
        <InputsNumber>12</InputsNumber>
        <Item Index="1">
            <Name>position.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>position.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>position.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="4">
            <Name>view.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="5">
            <Name>view.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="6">
            <Name>view.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="7">
            <Name>source.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="8">
            <Name>source.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="9">
            <Name>source.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="10">
            <Name>normal.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="11">
            <Name>normal.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="12">
            <Name>normal.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Inputs>
    <ScalingLayer>
        <ScalingNeuronsNumber>0</ScalingNeuronsNumber>
        <ScalingMethod>NoScaling</ScalingMethod>
    </ScalingLayer>
    <MultilayerPerceptron>
        <Architecture>12 20 10 3</Architecture>
        <LayersActivationFunction>HyperbolicTangent HyperbolicTangent Linear</LayersActivationFunction>
        <Parameters>-7.91742 -11.5196 -11.4407 2.71758 35.5155 -3.24573 -3.57073 36.0752 -8.09538 43.2441 0.153773 -2.53737 -0.036399 15.1509 -91.653 40.001 52.5155 -115.853 10.6383 10.4161 22.1899 115.633 123.806 -37.9753 -12.6025 12.1392 -0.292966 7.44708 -7.74073 3.59678 2.19718 -1.93761 0.932439 -0.48436 -5.74654 -3.08912 -2.48264 1.06442 -0.0351865 2.56706 18.9363 0.778378 -12.6805 34.9102 7.32796 10.7731 -41.59 7.36448 -6.64579 2.02102 5.25005 -0.586672 2.54742 17.3183 8.21397 -12.8534 20.3117 -4.97889 7.51344 -27.0509 -3.01614 -28.7932 0.405808 3.67567 -2.7201 3.14496 4.62369 -8.3359 -42.1666 -17.2861 3.62869 -0.106378 -6.07505 6.38942 -2.29077 14.5923 -5.7153 4.33321 -4.57702 -37.6177 -13.697 32.6978 -33.5875 -11.2488 -6.70213 35.8388 -12.7857 37.7421 1.28617 2.38613 -3.51588 1.75279 -1.28683 1.15408 -6.4336 -4.89237 7.26376 -4.80879 2.51154 8.60124 4.91769 0.0724961 -0.165093 2.28326 -2.62964 -19.953 -1.28703 -18.1843 -19.6096 -7.49176 -15.7092 8.34374 -3.99808 12.2169 0.192185 -2.67856 -0.961088 2.49998 -72.0901 26.5249 3.1181 -18.6655 9.37458 -4.10145 -5.07702 10.1718 -3.71222 0.791671 -0.749088 1.82805 -1.33505 35.437 -45.2045 38.9391 23.4459 -26.8212 26.4553 40.5662 2.26077 11.0652 -5.07775 1.57339 -4.65316 2.94958 13.1672 7.60913 0.161863 -0.822289 19.626 2.82103 -2.14687 6.87215 -5.6758 -27.4334 -8.80644 -37.1027 -2.39609 -72.0324 -4.58678 -8.66466 20.9719 -27.2659 7.37047 -11.5901 -4.77059 5.26894 10.8874 -6.92471 0.0117233 0.983173 -2.48997 9.10884 -6.85432 -6.58691 3.14167 -0.122369 -1.65067 8.66547 3.67074 -0.939497 0.967692 -1.20974 -1.00697 8.55292 -11.2028 9.5606 0.884101 -7.95574 3.40406 -0.34973 -1.13851 2.51327 2.38087 0.682248 1.71671 1.1728 12.5418 -7.04565 -2.28093 -0.0183879 0.649396 1.34337 -3.05751 -0.561225 -1.76772 1.28481 2.04702 1.37747 2.71901 283.694 157.747 -633.182 1.81258 25.935 9.3887 -5.82768 25.0253 13.7858 954.957 695.043 -330.69 4.74433 -31.6964 -1256.23 110.315 -41.2271 12.3135 -5.00863 15.4265 47.6133 50.6991 4.23136 10.5663 -4.40579 64.0042 -15.6171 -19.8346 -42.9672 -525.575 43.6222 40.0997 -283.594 55.9638 -388.646 4.74645 -0.81049 1.91725 -0.90286 1.82637 -1.57863 -14.568 5.17477 -3.24344 -0.586066 -1.85942 -0.85156 6.00511 64.9289 -20.1385 36.2087 42.1855 37.9725 8.3125 -41.984 -40.8504 -39.349 48.5466 53.7533 43.4486 40.421 52.1796 -42.2356 139.892 98.0763 41.6476 -39.3535 -33.8414 -36.1168 454.376 34.2264 -40.5721 -14.6619 4.42925 -14.5562 30.5995 18.9386 14.4683 9.38525 -10.6204 -16.7419 -6.23764 -15.5357 14.7686 8.81767 -3.83018 -16.5442 -1.18892 19.6632 30.319 -5.30343 -12.9903 11.9869 -20.6886 1.10245 -17.0546 -2.62768 5.10867 -4.63649 -23.5874 12.9142 -2.32693 13.9745 -17.2973 5.26784 -14.647 -2.33891 -17.4483 8.93008 -9.56408 1.56755 6.524 9.4377 9.68699 -20.2818 -2.06978 -16.7262 17.4054 -14.5094 17.9615 -15.3978 7.94434 -22.6411 1.46121 0.436597 2.5398 -15.4745 2.7785 -9.99276 20.5814 5.24447 33.9062 2.29502 0.925866 7.56658 -104.69 258.206 -92.3431 126.316 96.2636 104.186 95.8087 -103.187 -112.889 -107.911 -104.472 104.634 -96.8278 623.92 -99.4094 269.887 99.2068 -239.816 256.983 -107.289 -103.547 14.2981 -65.712 -59.2898 -43.9412 67.0029 71.2555 12.0666 -63.2953 15.2444 22.2598 50.8053 -22.6391 -553.091 -145.754 15.3562 -21.0571 19.7751 550.671 13.088 -31.1771 -17.38 17.0132 -0.816964 -8.8595 -28.4468 8.02653 -9.6818 24.5226 -6.79478 4.51358 6.42014 6.64517 -5.14701 20.4995 8.19434 15.8518 -8.56082 -25.7491 -36.1016 -6.99435 -43.1577 -73.7275 31.0819 33.3461 -40.0681 3.815 -15.0591 23.4332 -16.8152 -23.6754 48.8067 31.635 13.9195 -22.0173 17.9794 21.4843 30.9098 -39.0334 36.4423 -22.4757 -15.7333 -25.4932 -50.9042 -34.4822 -16.2226 31.9126 42.6506 28.0576 15.0592 -36.556 -29.3264 -34.3341 -36.0771 -55.5089 38.621 -36.1922 -46.0989 -36.7578 43.4718 37.6054 17.4409 -10.2415 -29.7614 66.08 20.0907 8.30659 -21.73 -7.75265 -4.85554 -8.12064 -1.85495 4.1033 10.9089 5.85135 3.28895 -18.4434 -28.6868 9.37219 21.174 9.25368 19.1287 19.5919 43.5783 -135.745 9.72702 -0.0219597 -0.00615763 0.0126508 0.00463436 -0.00615728 0.0188058 -0.010944 -0.0044318 0.013296 -0.00846694 -0.0364113 -0.001124 -0.00321515 0.00103396 0.00430728 -0.00277762 0.00396625 -0.000248153 -0.000713678 0.00107544 -0.000245799 -0.00509657 -0.00281378 0.0029503 0.00018927 0.00334989 0.00408039 -0.00279901 -0.000171298 -0.000286134 0.000260985 -6.63804e-05 -0.010755</Parameters>
    </MultilayerPerceptron>
    <UnscalingLayer>
        <UnscalingNeuronsNumber>0</UnscalingNeuronsNumber>
        <UnscalingMethod>NoUnscaling</UnscalingMethod>
    </UnscalingLayer>
    <Outputs>
        <OutputsNumber>3</OutputsNumber>
        <Item Index="1">
            <Name>R</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>G</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>B</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Outputs>
</NeuralNetwork>
