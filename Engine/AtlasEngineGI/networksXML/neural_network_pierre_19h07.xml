<NeuralNetwork>
    <Inputs>
        <InputsNumber>12</InputsNumber>
        <Item Index="1">
            <Name>position.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>position.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>position.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="4">
            <Name>view.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="5">
            <Name>view.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="6">
            <Name>view.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="7">
            <Name>source.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="8">
            <Name>source.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="9">
            <Name>source.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="10">
            <Name>normal.x</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="11">
            <Name>normal.y</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="12">
            <Name>normal.z</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Inputs>
    <ScalingLayer>
        <ScalingNeuronsNumber>0</ScalingNeuronsNumber>
        <ScalingMethod>NoScaling</ScalingMethod>
    </ScalingLayer>
    <MultilayerPerceptron>
        <Architecture>12 20 10 3</Architecture>
        <LayersActivationFunction>HyperbolicTangent HyperbolicTangent Linear</LayersActivationFunction>
        <Parameters>-8.2909 -12.1616 -11.2453 0.470492 34.2296 -4.83072 -6.12894 34.3094 -11.3802 43.9124 0.0827394 -2.99591 -0.0297297 15.3293 -91.0312 40.2962 52.4576 -114.953 12.4891 9.20465 23.23 116.726 123.713 -37.9254 -12.6127 11.9912 -0.376842 6.58895 -3.10289 0.798118 1.52021 -3.05813 0.486815 -0.81545 -6.07006 -2.93302 -2.24381 0.394101 0.129855 2.57896 18.8886 -0.0306602 -12.7111 35.0438 7.26633 10.6986 -41.4898 7.66665 -6.24517 2.04947 5.28119 -0.571542 2.85202 22.2464 0.999609 -2.01845 22.4413 -1.24536 6.73568 -25.4913 0.139908 -24.3845 0.0435512 3.66125 -3.07105 3.1572 4.63432 -8.42786 -42.1183 -17.3001 3.70288 -0.196294 -5.86654 6.59889 -2.32289 14.6038 -5.70115 4.31281 -4.4568 -37.1842 -13.1033 32.8079 -33.3101 -10.2665 -7.05068 36.2378 -11.5317 38.7141 1.28559 2.50538 -3.51449 1.74406 -5.09531 1.60763 -6.4308 -4.71414 7.52636 -5.34393 1.76533 8.39511 4.79569 0.689104 0.417212 1.86334 -2.59591 -19.3449 -0.660578 -18.9542 -19.6159 -7.05484 -15.3606 8.83474 -3.48654 12.3435 0.185705 -2.68127 -0.890402 2.49784 -72.1062 26.5146 3.12893 -18.7499 9.23404 -4.09816 -5.05314 10.0781 -3.74636 0.791443 -0.746824 1.83256 -1.417 35.2473 -45.311 39.2502 22.5833 -27.1952 27.1955 40.0451 1.81976 11.0321 -5.06213 1.60513 -4.66818 2.74042 14.1058 7.78922 0.671207 1.15225 18.3926 3.12501 -2.95065 5.4373 -5.87986 -27.0835 -9.13081 -37.3438 -0.391046 -4.11205 7.6315 -10.4778 4.43895 1.33819 -0.10441 -4.9578 -2.3825 -3.88089 0.239633 0.288103 0.788082 0.963844 -2.36363 8.88272 -6.73509 -7.21428 2.63038 1.02853 -0.923955 9.15023 3.62433 -0.763916 1.15919 -1.38676 -0.970844 8.01809 -9.03671 11.8985 1.09512 -7.68612 3.43545 -0.238451 -0.871255 2.82876 1.55989 -0.156685 1.66909 1.23078 12.4135 -6.62339 -2.58237 0.446516 2.10141 1.25714 -2.41242 0.473873 -1.20642 1.29194 1.78156 1.66032 2.71987 283.694 157.747 -633.182 1.81968 25.9384 9.38436 -5.82503 25.0259 13.7813 954.957 695.043 -330.69 4.74518 -31.6937 -1256.23 110.366 -41.1997 12.3344 -4.9387 15.4567 47.5423 50.6717 4.23136 10.5671 -4.40579 63.9947 -15.6437 -19.8514 -42.9751 -525.593 43.6027 40.0975 -283.604 55.8455 -388.634 4.74332 -0.81049 1.92662 -0.81101 5.20505 4.76346 2.52316 0.62217 -3.29587 -1.8444 1.70496 -1.90913 1.86092 -9.72281 -1.9913 3.88383 40.0366 40.5185 8.28262 -39.8351 -37.7548 -36.4943 46.1158 54.6885 41.2997 38.5246 50.0265 -40.0858 139.184 99.9415 39.4917 -37.2046 -31.1608 -38.3633 456.525 31.3758 -39.32 -16.1503 -9.71737 -14.8958 18.8729 16.8643 12.1473 -13.0867 -8.55809 -16.706 -8.5506 -11.6125 19.824 7.32924 0.53218 -17.119 3.10288 9.05493 8.08892 -5.26913 -9.93455 12.5109 -14.6519 7.05316 -9.87639 1.5291 6.43831 -8.69031 3.28477 8.2815 0.23808 3.5587 -22.8947 10.4345 -8.50331 -8.60767 -14.5644 3.08051 -8.29659 4.52799 0.580946 3.36956 -1.99792 -10.2953 0.830686 0.0287416 8.11403 2.92884 12.1615 -21.5524 -4.19346 -11.4433 -2.35673 6.53621 -6.87757 -6.40364 -1.19699 -0.0214314 8.37001 -7.46075 44.3507 0.0512313 2.00466 17.0892 -104.594 258.215 -92.4636 126.411 96.2752 104.357 95.8578 -103.376 -112.874 -107.992 -104.55 104.624 -96.7318 623.843 -99.3957 269.954 99.3948 -239.765 256.817 -107.298 -103.498 15.9588 -69.3519 -57.6295 -45.6016 63.0257 69.5693 15.2839 -66.2997 16.9047 24.4464 54.8683 -25.8669 -551.747 -140.499 17.0166 -23.1024 17.5899 552.015 11.6438 -27.5354 -18.1903 12.9892 1.90397 -3.41297 -43.1133 -2.31645 -2.20924 11.3041 -11.7464 9.46155 1.71301 9.99378 -9.36523 13.5092 2.33438 12.2831 -8.01999 -15.2437 -33.0644 -1.6506 -36.3279 -38.2299 25.4424 35.4832 -44.3145 14.0256 -21.2081 20.2463 -16.6151 -19.7908 46.8872 37.7789 13.8254 -22.6884 26.0665 25.1048 25.178 -45.4495 31.4026 -21.925 -20.1726 -21.2825 -46.2008 -37.797 -19.5869 31.6573 45.2674 25.7796 13.4499 -39.1433 -27.0203 -35.5835 -34.7905 -52.7343 33.0346 -39.507 -43.4419 -38.5107 45.5672 34.9826 15.1627 -17.3804 -28.7447 63.1 19.3716 7.48803 -22.9795 -5.43676 -5.90117 -6.99723 -0.984838 3.89205 9.63824 6.57823 2.06383 -18.9917 -29.4136 10.098 18.7234 11.4245 21.3219 20.2131 44.304 -135.018 10.5545 -9.55641 0.00349641 0.110112 -9.08326 0.0814106 -0.0097 -0.00745099 0.20483 0.367658 -0.0126867 -0.103113 -14.3966 -0.00304117 0.140231 -13.9659 0.0578919 -0.00198553 -0.00388459 0.206232 0.290318 -0.281779 0.13322 -0.681525 0.000495408 -0.0423467 -0.672229 0.0183233 -0.0029355 -0.00234701 -0.0226525 0.0745378 0.0975382 -0.0341157</Parameters>
    </MultilayerPerceptron>
    <UnscalingLayer>
        <UnscalingNeuronsNumber>0</UnscalingNeuronsNumber>
        <UnscalingMethod>NoUnscaling</UnscalingMethod>
    </UnscalingLayer>
    <Outputs>
        <OutputsNumber>3</OutputsNumber>
        <Item Index="1">
            <Name>R</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>G</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>B</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Outputs>
</NeuralNetwork>
